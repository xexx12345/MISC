{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xexx\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning:\n",
      "\n",
      "The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note to import from .py files, must follow structure\n",
    "# from <.py filename excluding '.py'> import <class name>\n",
    "# Optionslam creds: aspringfastlaner Options2018\n",
    "\n",
    "# Importing necessary models\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas.stats.moments as st\n",
    "from pandas import ExcelWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as ticker\n",
    "from lxml import html\n",
    "import requests\n",
    "import webbrowser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import csv\n",
    "import sched, time\n",
    "import pandas_datareader as datareader\n",
    "from pandas_datareader.data import Options\n",
    "from py_vollib.black_scholes_merton.implied_volatility import *\n",
    "import dash\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import plotly.plotly as py\n",
    "import plotly\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import skewnorm as skn\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model includes both an offensive and defensive universe:\n",
    "- Offensive: US equities (represented by SPY), international equities (EFA), emerging market equities (EEM) and US aggregate bonds (AGG). More on the seemingly odd inclusion of AGG as an offensive asset in a moment.\n",
    "- Defensive: US corporate bonds (LQD), US intermediate-term Treasuries (IEF) and US short-term Treasuries (SHY).\n",
    "- For all assets, at the close on the last trading day of the month, calculate a “momentum score” based on month-end data as follows:\n",
    "$$12(\\frac{p_0}{p_1} – 1) + 4(\\frac{p_0}{p_3} – 1) + 2(\\frac{p_0}{p_6} – 1) + (\\frac{p_0}{p_{12}} – 1)$$\n",
    " - Where p0 = the asset price at today’s close, p1 = the asset price at the close of the previous month, etc.\n",
    " - Note how this approach overweights more recent months. Doing the math, the most recent 1-month change (p0/p1 – 1) determines 40% of the momentum score, while the most distant month (p11/p12 – 1) determines just ~2%.\n",
    "\n",
    "- If all four of the offensive assets exhibit positive momentum scores, select the offensive asset with the highest score and allocate 100% of the portfolio to that asset at the close. Note the use of both absolute and relative momentum here, an idea popularized by Gary Antonacci as “Dual Momentum”. Why is that important? Historically, absolute momentum has done well minimizing losses, while relative momentum has helped in generating outsized returns.\n",
    "- If any of the four offensive assets exhibit negative momentum scores, select the defensive asset (LQD, IEF or SHY) with the highest score (regardless of whether the score is > 0) and allocate 100% of the portfolio to that asset at the close. As we do throughout this site, trades in SHY are assumed to be placed in cash, as it’s more relevant to today’s market given SHY’s low yields coupled with the impact of transaction costs and how frequently this strategy trades.\n",
    "- Hold the position until the final trading day of the following month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use six to import urllib so it is working for Python2/3\n",
    "from six.moves import urllib\n",
    "# If you don't want to use six, please comment out the line above\n",
    "# and use the line below instead (for Python3 only).\n",
    "#import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "import time\n",
    "\n",
    "'''\n",
    "Starting on May 2017, Yahoo financial has terminated its service on\n",
    "the well used EOD data download without warning. This is confirmed\n",
    "by Yahoo employee in forum posts.\n",
    "Yahoo financial EOD data, however, still works on Yahoo financial pages.\n",
    "These download links uses a \"crumb\" for authentication with a cookie \"B\".\n",
    "This code is provided to obtain such matching cookie and crumb.\n",
    "'''\n",
    "\n",
    "# Build the cookie handler\n",
    "cookier = urllib.request.HTTPCookieProcessor()\n",
    "opener = urllib.request.build_opener(cookier)\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "# Cookie and corresponding crumb\n",
    "_cookie = None\n",
    "_crumb = None\n",
    "\n",
    "_headers={'User-Agent': 'Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 Firefox/2.0.0.11'}\n",
    "\n",
    "def get_cookie_crumb(ticker):\n",
    "    '''\n",
    "    This function perform a query and extract the matching cookie and crumb.\n",
    "    '''\n",
    "\n",
    "    # Perform a Yahoo financial lookup on SP500\n",
    "    req = urllib.request.Request('https://finance.yahoo.com/quote/' + ticker, headers=_headers)\n",
    "    f = urllib.request.urlopen(req)\n",
    "    alines = f.read().decode('utf-8')\n",
    "\n",
    "    # Extract the crumb from the response\n",
    "    global _crumb\n",
    "    cs = alines.find('CrumbStore')\n",
    "    cr = alines.find('crumb', cs + 10)\n",
    "    cl = alines.find(':', cr + 5)\n",
    "    q1 = alines.find('\"', cl + 1)\n",
    "    q2 = alines.find('\"', q1 + 1)\n",
    "    crumb = alines[q1 + 1:q2]\n",
    "    _crumb = crumb\n",
    "\n",
    "    # Extract the cookie from cookiejar\n",
    "    global cookier, _cookie\n",
    "    for c in cookier.cookiejar:\n",
    "        if c.domain != '.yahoo.com':\n",
    "            continue\n",
    "        if c.name != 'B':\n",
    "            continue\n",
    "    _cookie = c.value\n",
    "\n",
    "    # Print the cookie and crumb\n",
    "    # print('Cookie:', _cookie)\n",
    "    # print('Crumb:', _crumb)\n",
    "    return _crumb\n",
    "\n",
    "\n",
    "def yahoo_historical(ticker = 'SPY', start_date = dt.datetime(2016,1,1)):\n",
    "    # Using requests to ping yahoo finance to retrieve \n",
    "    # historical data table\n",
    "    start_date_unix = int(time.mktime(start_date.timetuple()))\n",
    "    \n",
    "    # Getting cookie crumb for yahoo finance query\n",
    "    get_cookie_crumb(ticker)\n",
    "    \n",
    "    if ticker == 'VVIX':\n",
    "        site = 'https://query1.finance.yahoo.com/v7/finance/download/%5EVVIX?period1={0}&period2='.format(start_date_unix) + str(int(time.time())) + '&interval=1d&events=history&crumb=' + get_cookie_crumb('^VVIX').replace('\\\\','')\n",
    "    elif ticker == 'SPX':\n",
    "        site = 'https://query1.finance.yahoo.com/v7/finance/download/%5EGSPC?period1={0}&period2='.format(start_date_unix) + str(int(time.time())) + '&interval=1d&events=history&crumb=' + get_cookie_crumb('^GSPC').replace('\\\\','')\n",
    "    else:\n",
    "        site = 'https://query1.finance.yahoo.com/v7/finance/download/{0}?period1={1}&period2='.format(ticker,start_date_unix) + str(int(time.time())) + '&interval=1d&events=history&crumb=' + get_cookie_crumb(ticker).replace('\\\\','')\n",
    "    \n",
    "    df = pd.read_csv(site, index_col = 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ticker_list = ['AGG','EFA,'EEM'']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
